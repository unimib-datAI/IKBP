version: "3"
services:
  postgres:
    restart: $RESTART_POLICY
    image: postgres:14
    networks:
      - caddy_net
    environment:
      POSTGRES_PASSWORD: $POSTGRES_PASSWORD
    volumes:
      - ./postgres/data:/var/lib/postgresql/data
      - "./postgres/init.sql:/docker-entrypoint-initdb.d/init.sql"

  mongo:
    restart: $RESTART_POLICY
    image: mongo:4.4.6 # mongo 5 requires cpu supports AVX
    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: $MONGO_ROOT_PASSWORD
      MONGO_INITDB_DATABASE: main
      MONGO_INITDB_USERNAME: usr
      MONGO_INITDB_PASSWORD: $MONGO_PASSWORD
      MONGO: $MONGO
    volumes:
      - ./mongo/data:/data/db
      - ./mongo/initdb.d:/docker-entrypoint-initdb.d/
    ports:
      - 127.0.0.1:27017:27017

  documents:
    restart: $RESTART_POLICY
    build: documents
    environment:
      DOCS_PORT: 3001
      ENABLE_AUTH: false
      MONGO: $MONGO
    volumes:
      - ./documents/src:/app/src
    ports:
      - 3001:3001
  documents_demo:
    restart: $RESTART_POLICY
    build: documents
    environment:
      DOCS_PORT: 3001
      ENABLE_AUTH: false
      MONGO: $MONGO_DOCUMENTS
    volumes:
      - ./documents/src:/app/src
    ports:
      - 3002:3001
  indexer:
    restart: $RESTART_POLICY
    # image: rpozzi/blink_indexer
    build:
      context: ./indexer
      dockerfile: Dockerfile
    networks:
      - caddy_net
    volumes:
      - /mnt/data/models:/home/app/models
      - ./indexer/main.py:/home/app/main.py

    environment:
      INDEXER_INDEX: $INDEXER_INDEX
      POSTGRES_PASSWORD: $POSTGRES_PASSWORD
      INDEXER_VECTOR_SIZE: $INDEXER_VECTOR_SIZE
      INDEXER_LANGUAGE: $INDEXER_LANGUAGE
    depends_on:
      - postgres
    # command: python main.py --host 0.0.0.0 --port 80 --index $INDEXER_INDEX --postgres postgres://postgres:$POSTGRES_PASSWORD@postgres:5432/postgres --vector-size $INDEXER_VECTOR_SIZE --language $INDEXER_LANGUAGE

  pipeline:
    restart: $RESTART_POLICY
    build: pipelinehelper
    environment:
      PIPELINE_ARGS: $PIPELINE_ARGS
    volumes:
      - ./pipelinehelper/main.py:/home/app/main.py

  spacyner:
    restart: $RESTART_POLICY
    build: ./spacyner
    environment:
      SPACY_MODEL: $SPACY_MODEL
      SPACY_TAG: $SPACY_TAG
      SPACY_SENTER: $SPACY_SENTER
      SPACY_WORKERS: $SPACY_WORKERS
      SPACY_TIMEOUT: $SPACY_TIMEOUT
      SPACY_GPU: $SPACY_GPU
    volumes:
      - /mnt/data/models:/home/app/models
      - ./spacyner/main.py:/home/app/main.py
    networks:
      - caddy_net
    ports:
      - 3222:80
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
  biencoder:
    restart: $RESTART_POLICY
    build: ./biencoder
    environment:
      BIENCODER_MODEL: $BIENCODER_MODEL
      BIENCODER_CONFIG: $BIENCODER_CONFIG
    networks:
      - caddy_net
    volumes:
      - /mnt/data/models:/home/app/models
      - ./biencoder/main.py:/home/app/main.py
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    # command: python __main__.py --host 0.0.0.0 --port 80 --model $SPACY_MODEL
  consolidation:
    restart: $RESTART_POLICY
    build: ./consolidation
    networks:
      - caddy_net
    volumes:
      - /mnt/data/models:/home/app/models
      - ./consolidation/:/home/app/

  nilpredictor:
    restart: $RESTART_POLICY
    build: ./nilpredictor
    networks:
      - caddy_net
    environment:
      NILPREDICTOR_ARGS: $NILPREDICTOR_ARGS
    volumes:
      - /mnt/data/models:/home/app/models
      - ./nilpredictor/:/home/app/
  clustering:
    restart: $RESTART_POLICY
    build: ./clustering
    networks:
      - caddy_net
    environment:
      CLUSTERING_MODEL: $CLUSTERING_MODEL
    volumes:
      - /mnt/data/models:/home/app/models
      - ./clustering/:/home/app/
  caddy:
    restart: $RESTART_POLICY
    image: caddy:2
    ports:
      - "10881:80"
    networks:
      - caddy_net
    volumes:
      - ./caddy/Caddyfile:/etc/caddy/Caddyfile
      - ./caddy/site:/srv
      - ./caddy/data:/data
      - ./caddy/config:/config
  ui_demo:
    restart: $RESTART_POLICY
    build:
      context: giustizia-ui
      args:
        ACCESS_USERNAME: $UI_DEMO_ACCESS_USERNAME
        ACCESS_PASSWORD: $UI_DEMO_ACCESS_PASSWORD
        API_BASE_URI: ${DEMO_PIPELINE_ADDRESS}/api
        API_USERNAME: ""
        API_PASSWORD: ""
        NEXTAUTH_SECRET: $UI_NEXTAUTH_SECRET
        NEXTAUTH_URL: $DEMO_UI_NEXTAUTH_URL
        NEXT_PUBLIC_BASE_PATH: $UI_NEXT_PUBLIC_BASE_PATH
        NEXT_PUBLIC_FULL_PATH: $DEMO_UI_NEXT_PUBLIC_FULL_PATH
        API_LLM: $UI_API_LLM
        API_INDEXER: $UI_API_INDEXER
        VARIANT: "bologna"
        TEXT_GENERATION: $TEXT_GENERATION_ADDR
        ELASTIC_INDEX: "bologna"
    ports:
      - $DEMO_LISTEN_UI:3000
      # - 127.0.0.1:9229:9229
    environment:
      ACCESS_USERNAME: $UI_DEMO_ACCESS_USERNAME
      ACCESS_PASSWORD: $UI_DEMO_ACCESS_PASSWORD
      API_BASE_URI: ${DEMO_PIPELINE_ADDRESS}/api
      API_USERNAME: ""
      API_PASSWORD: ""
      NEXTAUTH_SECRET: $UI_NEXTAUTH_SECRET
      NEXTAUTH_URL: $DEMO_UI_NEXTAUTH_URL
      NEXT_PUBLIC_BASE_PATH: $UI_NEXT_PUBLIC_BASE_PATH
      NEXT_PUBLIC_FULL_PATH: $DEMO_UI_NEXT_PUBLIC_FULL_PATH
      API_LLM: $UI_API_LLM
      API_INDEXER: $UI_API_INDEXER
      VARIANT: "bologna"
      TEXT_GENERATION: $TEXT_GENERATION_ADDR
      HOST: host.docker.internal
      ELASTIC_INDEX: "bologna"
    extra_hosts:
      - "host.docker.internal:host-gateway"

    volumes:
      - ./giustizia-ui/modules:/app/modules
      - ./giustizia-ui/server:/app/server
      - ./giustizia-ui/pages:/app/pages
      - ./giustizia-ui/components:/app/components
      - ./giustizia-ui/lib:/app/lib
      - ./giustizia-ui/package.json:/app/package.json
    # command: sleep 7200

  ui:
    restart: $RESTART_POLICY
    build:
      context: giustizia-ui
      args:
        ACCESS_USERNAME: $UI_ACCESS_USERNAME
        ACCESS_PASSWORD: $UI_ACCESS_PASSWORD
        API_BASE_URI: ${PIPELINE_ADDRESS}/api
        API_USERNAME: ""
        API_PASSWORD: ""
        NEXTAUTH_SECRET: $UI_NEXTAUTH_SECRET
        NEXTAUTH_URL: $UI_NEXTAUTH_URL
        NEXT_PUBLIC_BASE_PATH: $UI_NEXT_PUBLIC_BASE_PATH
        NEXT_PUBLIC_FULL_PATH: $UI_NEXT_PUBLIC_FULL_PATH
        API_LLM: $UI_API_LLM
        API_INDEXER: $UI_API_INDEXER
        VARIANT: $UI_VARIANT
        TEXT_GENERATION: $TEXT_GENERATION_ADDR
    ports:
      - $LISTEN_UI:3000
      - 127.0.0.1:9229:9229
    environment:
      ACCESS_USERNAME: $UI_ACCESS_USERNAME
      ACCESS_PASSWORD: $UI_ACCESS_PASSWORD
      API_BASE_URI: ${PIPELINE_ADDRESS}/api
      API_USERNAME: ""
      API_PASSWORD: ""
      NEXTAUTH_SECRET: $UI_NEXTAUTH_SECRET
      NEXTAUTH_URL: $UI_NEXTAUTH_URL
      NEXT_PUBLIC_BASE_PATH: $UI_NEXT_PUBLIC_BASE_PATH
      NEXT_PUBLIC_FULL_PATH: $UI_NEXT_PUBLIC_FULL_PATH
      API_LLM: $UI_API_LLM
      API_INDEXER: $UI_API_INDEXER
      VARIANT: $UI_VARIANT
      TEXT_GENERATION: $TEXT_GENERATION_ADDR
      HOST: host.docker.internal
    extra_hosts:
      - "host.docker.internal:host-gateway"

    volumes:
      - ./giustizia-ui/modules:/app/modules
      - ./giustizia-ui/server:/app/server
      - ./giustizia-ui/pages:/app/pages
      - ./giustizia-ui/components:/app/components
      - ./giustizia-ui/lib:/app/lib
      - ./giustizia-ui/package.json:/app/package.json
    # command: sleep 7200

  text-generation:
    build:
      context: ./text-generation
      dockerfile: Dockerfile
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           capabilities: [ gpu ]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    environment:
      # - MODEL_NAME=${TEXT_GENERATION_MODEL}
      - GPU_LAYERS=${TEXT_GENERATION_GPU_LAYERS}
    ports:
      - 10.0.0.108:7862:7862
    volumes:
      - ./models/text-generation:/workspace/models
      # - ./text-generation/src:/workspace

  es:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.13.3
    restart: $RESTART_POLICY
    environment:
      - xpack.security.enabled=false
      ### Avoid test failures due to small disks. NOT SUITABLE FOR PRODUCTION.
      - cluster.routing.allocation.disk.threshold_enabled=false
      - cluster.routing.allocation.disk.watermark.low=3mb
      - cluster.routing.allocation.disk.watermark.high=2mb
      - cluster.routing.allocation.disk.watermark.flood_stage=1mb
      - cluster.info.update.interval=1m
      ###
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms4096m -Xmx4096m
      - http.max_content_length=200mb
    ports:
      - 9201:9200
    volumes:
      - ./elasticsearch/data:/usr/share/elasticsearch/data

  qavectorizer:
    build:
      context: ./qavectorizer
      dockerfile: Dockerfile
    depends_on:
      - es
    restart: $RESTART_POLICY
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           capabilities: [ gpu ]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    environment:
      - HOST_BASE_URL=${HOST_BASE_URL}
      - INDEXER_SERVER_PORT=7863
      - DOCS_PORT=${DOCS_PORT}
      - CHROMA_PORT=${CHROMA_PORT}
      - ELASTIC_PORT=${ELASTIC_PORT}
      - SENTENCE_TRANSFORMER_EMBEDDING_MODEL=${SENTENCE_TRANSFORMER_EMBEDDING_MODEL}
      - SENTENCE_TRANSFORMER_DEVICE=${SENTENCE_TRANSFORMER_DEVICE}
      - OGG2NAME_INDEX=${OGG2NAME_INDEX}
      - NVIDIA_VISIBLE_DEVICES=all
    ports:
      - ${QAVECTORIZER_ADDR}:7863
    volumes:
      - ./qavectorizer/src:/workspace
      - ./models:/root/models
      - ./models/qavectorizer:/root/.cache/huggingface
networks:
  caddy_net:
    driver: bridge
