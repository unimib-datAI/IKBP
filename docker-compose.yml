version: "3"
services:

  postgres:
    restart: $RESTART_POLICY
    image: postgres:14
    environment:
      POSTGRES_PASSWORD: $POSTGRES_PASSWORD
    volumes:
      - ./postgres/data:/var/lib/postgresql/data
      - "./postgres/init.sql:/docker-entrypoint-initdb.d/init.sql"

  mongo:
    restart: $RESTART_POLICY
    image: mongo:4.4.6 # mongo 5 requires cpu supports AVX
    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: $MONGO_ROOT_PASSWORD
      MONGO_INITDB_DATABASE: main
      MONGO_INITDB_USERNAME: usr
      MONGO_INITDB_PASSWORD: $MONGO_PASSWORD
      MONGO: $MONGO
    volumes:
      - ./mongo/data:/data/db
      - ./mongo/initdb.d:/docker-entrypoint-initdb.d/
    ports:
      - 127.0.0.1:27017:27017
  documents:
    restart: $RESTART_POLICY
    build: documents
    environment:
      DOCS_PORT: 3001
      ENABLE_AUTH: false
      MONGO: $MONGO
    volumes:
      - ./documents/src:/app/src

  indexer:
    restart: $RESTART_POLICY
    # image: rpozzi/blink_indexer
    build:
        context: ./indexer
        dockerfile: Dockerfile
    volumes:
      - ${LOCAL_WORKSPACE_FOLDER}/models:/home/app/models
      - ./indexer/main.py:/home/app/main.py
    environment:
      INDEXER_INDEX: $INDEXER_INDEX
      POSTGRES_PASSWORD: $POSTGRES_PASSWORD
      INDEXER_VECTOR_SIZE: $INDEXER_VECTOR_SIZE
      INDEXER_LANGUAGE: $INDEXER_LANGUAGE
    depends_on:
      - postgres
    # command: python main.py --host 0.0.0.0 --port 80 --index $INDEXER_INDEX --postgres postgres://postgres:$POSTGRES_PASSWORD@postgres:5432/postgres --vector-size $INDEXER_VECTOR_SIZE --language $INDEXER_LANGUAGE
    # command: sleep 3600

  pipeline:
    restart: $RESTART_POLICY
    build: pipelinehelper
    environment:
      PIPELINE_ARGS: $PIPELINE_ARGS
    volumes:
      - ./pipelinehelper/main.py:/home/app/main.py

  spacyner:
    restart: $RESTART_POLICY
    build: ./spacyner
    environment:
      SPACY_MODEL: $SPACY_MODEL
      SPACY_TAG: $SPACY_TAG
      SPACY_SENTER: $SPACY_SENTER
      SPACY_WORKERS: $SPACY_WORKERS
      SPACY_TIMEOUT: $SPACY_TIMEOUT
      SPACY_GPU: $SPACY_GPU
    volumes:
      - ${LOCAL_WORKSPACE_FOLDER}/models:/home/app/models
      - ./spacyner/main.py:/home/app/main.py
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [ gpu ]
    # command: python __main__.py --host 0.0.0.0 --port 80 --model $SPACY_MODEL

  caddy:
    restart: $RESTART_POLICY
    image: caddy:2
    ports:
      - "$CADDY_LISTEN_HTTP:80"
    volumes:
      - ./caddy/Caddyfile:/etc/caddy/Caddyfile
      - ./caddy/site:/srv
      - ./caddy/data:/data
      - ./caddy/config:/config

  ui:
    restart: $RESTART_POLICY
    build:
      context: giustizia-ui
      args:
        ACCESS_USERNAME: $UI_ACCESS_USERNAME
        ACCESS_PASSWORD: $UI_ACCESS_PASSWORD
        API_BASE_URI: ${PIPELINE_ADDRESS}/api
        API_USERNAME: ""
        API_PASSWORD: ""
        NEXTAUTH_SECRET: $UI_NEXTAUTH_SECRET
        NEXTAUTH_URL: $UI_NEXTAUTH_URL
        NEXT_PUBLIC_BASE_PATH: $UI_NEXT_PUBLIC_BASE_PATH
        NEXT_PUBLIC_FULL_PATH: $UI_NEXT_PUBLIC_FULL_PATH
        API_LLM: $UI_API_LLM
        API_INDEXER: $UI_API_INDEXER
        VARIANT: $UI_VARIANT
    ports:
      - $LISTEN_UI:3000
    environment:
      ACCESS_USERNAME: $UI_ACCESS_USERNAME
      ACCESS_PASSWORD: $UI_ACCESS_PASSWORD
      API_BASE_URI: ${PIPELINE_ADDRESS}/api
      API_USERNAME: ""
      API_PASSWORD: ""
      NEXTAUTH_SECRET: $UI_NEXTAUTH_SECRET
      NEXTAUTH_URL: $UI_NEXTAUTH_URL
      NEXT_PUBLIC_BASE_PATH: $UI_NEXT_PUBLIC_BASE_PATH
      NEXT_PUBLIC_FULL_PATH: $UI_NEXT_PUBLIC_FULL_PATH
      API_LLM: $UI_API_LLM
      API_INDEXER: $UI_API_INDEXER
      VARIANT: $UI_VARIANT

    volumes:
      - ./giustizia-ui/modules:/app/modules
      - ./giustizia-ui/server:/app/server
      - ./giustizia-ui/pages:/app/pages
        #command: sleep 7200

  text-generation:
    build:
      context: ./text-generation
      dockerfile: Dockerfile
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [ gpu ]
    environment:
      # - MODEL_NAME=${TEXT_GENERATION_MODEL}
      - GPU_LAYERS=${TEXT_GENERATION_GPU_LAYERS}
    ports:
      - $TEXT_GENERATION_ADDR:7862
    volumes:
      - ./models/text-generation:/workspace/models
      # - ./text-generation/src:/workspace

  localai:
    image: quay.io/go-skynet/local-ai:v2.0.0-cublas-cuda11
    tty: true # enable colorized logs
    restart: $RESTART_POLICY
    volumes:
      - ./models/localai/models:/models
      - ./models/localai/images/:/tmp/generated/images/
    command: ["/usr/bin/local-ai" ]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [ gpu ]
    ports:
      - $LOCALAI_ADDR:8080
    environment:
      MODELS_PATH: $LOCALAI_MODELS_PATH
      BUILD_TYPE: $LOCALAI_BUILD_TYPE


  es:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.13.3
    restart: $RESTART_POLICY
    environment:
      - xpack.security.enabled=false
      ### Avoid test failures due to small disks. NOT SUITABLE FOR PRODUCTION.
      - cluster.routing.allocation.disk.threshold_enabled=false
      - cluster.routing.allocation.disk.watermark.low=3mb
      - cluster.routing.allocation.disk.watermark.high=2mb
      - cluster.routing.allocation.disk.watermark.flood_stage=1mb
      - cluster.info.update.interval=1m
      ###
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms4096m -Xmx4096m
    ports:
      - ${ELASTIC_PORT}:${ELASTIC_PORT}
    volumes:
      - ./elasticsearch/data:/usr/share/elasticsearch/data

  qavectorizer:
    build:
      context: ./qavectorizer
      dockerfile: Dockerfile
    depends_on:
      - es
    restart: $RESTART_POLICY
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [ gpu ]
    environment:
      - HOST_BASE_URL=${HOST_BASE_URL}
      - INDEXER_SERVER_PORT=7863
      - DOCS_PORT=${DOCS_PORT}
      - CHROMA_PORT=${CHROMA_PORT}
      - ELASTIC_PORT=${ELASTIC_PORT}
      - SENTENCE_TRANSFORMER_EMBEDDING_MODEL=${SENTENCE_TRANSFORMER_EMBEDDING_MODEL}
      - SENTENCE_TRANSFORMER_DEVICE=${SENTENCE_TRANSFORMER_DEVICE}
      - OGG2NAME_INDEX=${OGG2NAME_INDEX}
    ports:
      - ${QAVECTORIZER_ADDR}:7863
    volumes:
      - ./qavectorizer/src:/workspace
      - ./models:/root/models
      - ./models/qavectorizer:/root/.cache/huggingface